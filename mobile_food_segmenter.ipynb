{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Food Scoring based on Semantic Image Segmentation\n"
      ],
      "metadata": {
        "id": "gX5nDswTo1z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "This notebook provides the segmentation/classification model, the Nutrition5k test set, as well as some realistic data collected by our team members (and team members' friends/families) throughout the day.\n",
        "\n",
        "*   `data_real` contains our own collected data\n",
        "*   `nutrition5k` contains the Nutrition5k dataset test split\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BoY0usprpEZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openfoodfacts"
      ],
      "metadata": {
        "id": "T6r9lCSixGPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import ast\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import openfoodfacts\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.patches as mpatches\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "from transformers import DPTForDepthEstimation, DPTFeatureExtractor\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Mxar67GlBnY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM4ub4AtBYig"
      },
      "outputs": [],
      "source": [
        "def computeVolume(filename):\n",
        "    # # Check if filename is passed\n",
        "    # if len(sys.argv) < 2:\n",
        "    #     print(\"Please provide a filename as a command line argument.\")\n",
        "    #     return\n",
        "\n",
        "    # print(\"Filename:\", filename)\n",
        "\n",
        "    # Rest of your function using filename\n",
        "\n",
        "    model_filename = '/content/mobile-food-segmenter.tar.gz'\n",
        "    extracted_folder_path = 'extracted_model'\n",
        "\n",
        "    if not os.path.exists(extracted_folder_path):\n",
        "        with tarfile.open(model_filename, 'r:gz') as tar:\n",
        "            tar.extractall(path=extracted_folder_path)\n",
        "        print(\"Model extracted\")\n",
        "\n",
        "    # Load the image\n",
        "    image_path = filename\n",
        "    image = tf.image.decode_image(tf.io.read_file(image_path))\n",
        "    image = tf.image.resize(image, [513, 513])\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    print(\"Image loaded\")\n",
        "\n",
        "    # Check if the image is 3-channel RGB\n",
        "    if image.shape[-1] != 3:\n",
        "        print(\"Make sure your image is RGB.\")\n",
        "\n",
        "    # Expand dimensions for batch\n",
        "    image_batch = tf.expand_dims(image, 0)\n",
        "\n",
        "    # Load the local model with specified output keys\n",
        "    m = hub.KerasLayer(extracted_folder_path, signature_outputs_as_dict=True)\n",
        "    print(\"Model loaded\")\n",
        "\n",
        "    # Use the model\n",
        "    results = m(image_batch)\n",
        "    print(\"Model used\")\n",
        "\n",
        "    segmentation_probs = results['food_group_segmenter:semantic_probabilities'][0]\n",
        "    segmentation_mask = results['food_group_segmenter:semantic_predictions'][0]\n",
        "\n",
        "    return segmentation_probs, segmentation_mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_to_dict(file_path, example_path):\n",
        "    data_dict = {}\n",
        "    serving_sizes = {}\n",
        "    example_foods = {}\n",
        "\n",
        "    with open(file_path, 'r') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)  # Skip the header row\n",
        "        for row in csvreader:\n",
        "            key, label, serving_size = row\n",
        "            data_dict[int(key)] = label.split('|')\n",
        "            serving_sizes[int(key)] = serving_size\n",
        "\n",
        "    with open(example_path, 'r') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)  # Skip the header row\n",
        "        for row in csvreader:\n",
        "            key, ex1, ex2, ex3 = row\n",
        "            examples = [ex1, ex2, ex3]\n",
        "            example_foods[int(key)] = examples\n",
        "\n",
        "    return data_dict, serving_sizes, example_foods"
      ],
      "metadata": {
        "id": "nRaCJXM5ivno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_labels(segmentation_mask, k=3):\n",
        "    # Flatten the segmentation mask\n",
        "    flat_mask = segmentation_mask.flatten()\n",
        "    exclude_labels = [0, 23, 24, 25] # exclude background, food containers, cutlery\n",
        "\n",
        "    # Count the occurrence of each unique label in the mask\n",
        "    labels, counts = np.unique(flat_mask, return_counts=True)\n",
        "\n",
        "    # Sort the counts in descending order\n",
        "    exclusion_mask = np.isin(labels, exclude_labels, invert=True)\n",
        "\n",
        "    labels = labels[exclusion_mask]\n",
        "    counts = counts[exclusion_mask]\n",
        "\n",
        "    sorted_indices = np.argsort(-counts)\n",
        "\n",
        "    # Get the top three labels\n",
        "    top_three_labels = labels[sorted_indices[:k]]\n",
        "\n",
        "    return top_three_labels"
      ],
      "metadata": {
        "id": "AQeXeq9qMzig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import center_of_mass\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def visualize_segmentation_mask(segmentation_mask, filename):\n",
        "    k = 3\n",
        "\n",
        "    # Load and preprocess the image as per the provided method\n",
        "    image_path = filename\n",
        "    image = tf.image.decode_image(tf.io.read_file(image_path))\n",
        "    image = tf.image.resize(image, [513, 513])\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    print(\"Image loaded\")\n",
        "\n",
        "    # Assuming segmentation_mask is a TensorFlow tensor, convert it to numpy\n",
        "    if isinstance(segmentation_mask, tf.Tensor):\n",
        "        segmentation_mask = segmentation_mask.numpy()\n",
        "\n",
        "    # Get the top k labels from the segmentation mask\n",
        "    top_k_labels = get_top_k_labels(segmentation_mask, k)\n",
        "\n",
        "    # Mask to only show top k labels in the segmentation\n",
        "    top_k_mask = np.isin(segmentation_mask, top_k_labels)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))  # Adjusted for side-by-side view\n",
        "\n",
        "    # Display the original image on the left\n",
        "    ax[0].imshow(image)\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Display the segmented image on the right, filtered by top k labels\n",
        "    ax[1].imshow(image, alpha=0.5)  # Original image slightly transparent\n",
        "    ax[1].imshow(top_k_mask * segmentation_mask, cmap='jet', alpha=0.8)  # Segmented top k labels\n",
        "    ax[1].set_title(f'Top {k} Food Groups')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    unique_segments = np.unique(segmentation_mask[top_k_mask])\n",
        "    for segment in unique_segments:\n",
        "        # Find the center of mass for each top k segment\n",
        "        centroid = center_of_mass(segmentation_mask == segment)\n",
        "\n",
        "        # Display the segment number at its centroid on the segmented image\n",
        "        ax[1].text(centroid[1], centroid[0], str(segment), color='white', ha='center', va='center')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cGMpmyYfCp-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User-Agent is mandatory\n",
        "api = openfoodfacts.API(user_agent=\"Grocerly/Prototype\")\n",
        "\n",
        "\n",
        "def fetch_data_from_api(query):\n",
        "    print(f\"Query term: {query}\")\n",
        "    query_data = api.product.text_search(query).get(\"products\")\n",
        "\n",
        "    calories, carbs, fat, protein, sugar, salt = extract_nutrient_data(query_data)\n",
        "    return calories, carbs, fat, protein, sugar, salt\n",
        "\n",
        "    # print(f\"API return: {json_data}\")\n",
        "    # if int(json_data[\"nutrients\"][\"nova-group\"]) != 1:\n",
        "    #     recommend_healthy_suggestions(json_data, int(json_data[\"nutrients\"][\"nova-group\"]), 3)\n",
        "\n",
        "\n",
        "def extract_nutrient_data(api_obj):\n",
        "    allergens = api_obj[0].get(\"allergens\")\n",
        "    nutrients = api_obj[0].get(\"nutriments\")\n",
        "\n",
        "    json_data = {\n",
        "        \"name\": api_obj[0].get(\"abbreviated_product_name\"),\n",
        "        \"categories\": [],\n",
        "        \"nutrients\": {\n",
        "            \"nova-group\": nutrients[\"nova-group\"],\n",
        "            \"proteins_100g\": nutrients[\"proteins_100g\"],\n",
        "            \"saturated-fat_100g\": nutrients[\"saturated-fat_100g\"],\n",
        "            \"fat_100g\": nutrients[\"fat_100g\"],\n",
        "            \"energy_100g\": nutrients[\"energy_100g\"],\n",
        "            \"carbohydrates_100g\": nutrients[\"carbohydrates_100g\"]\n",
        "        },\n",
        "        \"allergens\": allergens\n",
        "    }\n",
        "\n",
        "    for i in range(3):\n",
        "        if i < len(api_obj[0].get(\"categories_hierarchy\")):\n",
        "            json_data[\"categories\"].append(api_obj[0].get(\"categories_hierarchy\")[i])\n",
        "\n",
        "    optional_nutrients = [\"salt_100g\", \"sugars_100g\", \"ph_100g\"]\n",
        "    for nutrient in optional_nutrients:\n",
        "        if nutrient in nutrients:\n",
        "            json_data[\"nutrients\"][nutrient] = nutrients[nutrient]\n",
        "\n",
        "    json_string = json.dumps(json_data)\n",
        "\n",
        "    # print(f\"API Response: {json_string}\")\n",
        "\n",
        "    nutrients = json_data.get('nutrients', {})\n",
        "    energy = nutrients.get('energy_100g', 'Not available') # kJ\n",
        "    carbs = nutrients.get('carbohydrates_100g', 'Not available')\n",
        "    fat = nutrients.get('fat_100g', 'Not available')\n",
        "    protein = nutrients.get('proteins_100g', 'Not available')\n",
        "    sugar = nutrients.get('sugars_100g', 'Not available')\n",
        "    salt = nutrients.get('salt_100g', 'Not available')\n",
        "\n",
        "    # print(calories, carbs, fat, protein)\n",
        "    calories = energy / 4.184\n",
        "    return calories, carbs, fat, protein, sugar, salt\n"
      ],
      "metadata": {
        "id": "Hm0Qo__YwzIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/data_real/'\n",
        "\n",
        "label_dict, serving_sizes, example_foods = read_csv_to_dict('/content/seefood_mobile_food_segmenter_V1_labelmap.csv', '/content/example_foods.csv')\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory_path):\n",
        "    if os.path.isfile(os.path.join(directory_path, filename)):\n",
        "      print(filename)\n",
        "\n",
        "      total_cals = 0\n",
        "      total_protein = 0\n",
        "      total_carbs = 0\n",
        "      total_fat = 0\n",
        "      total_salt = 0\n",
        "      total_sugar = 0\n",
        "\n",
        "      with tqdm(total=100, desc=\"Computing Volume\") as pbar:\n",
        "        class_probabilities, mask = computeVolume(os.path.join(directory_path, filename))\n",
        "        pbar.update(100)\n",
        "\n",
        "        visualize_segmentation_mask(mask, os.path.join(directory_path, filename))\n",
        "        top_labels = get_top_k_labels(mask.numpy(), k=3)\n",
        "\n",
        "        # TODO: Improve presentation\n",
        "        print(\"Top labels:\")\n",
        "        for top_label in top_labels:\n",
        "            label_value = label_dict.get(top_label, \"Label not found\")  # Retrieve the value from label_dict or display a message if not found\n",
        "            print(f\"{label_value}\")\n",
        "\n",
        "            # API-Call\n",
        "            calories, carbs, fat, protein, sugar, salt = fetch_data_from_api(np.random.choice(example_foods[top_label], 1))\n",
        "            total_cals += calories\n",
        "            total_carbs += carbs\n",
        "            total_fat += fat\n",
        "            total_protein += protein\n",
        "            total_sugar += sugar\n",
        "            total_salt += salt\n",
        "    print(f\"Totals for meal: {total_cals} kcal, {total_carbs} C, {total_protein} P, {total_fat} F, {total_sugar} sugar, {total_salt} salt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CuRbPdPKB8uT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}